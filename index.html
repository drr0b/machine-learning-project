<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Machine-learning-project : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Machine-learning-project</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/drr0b/machine-learning-project">View on GitHub</a>

          <h1 id="project_title">Machine-learning-project</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/drr0b/machine-learning-project/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/drr0b/machine-learning-project/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>




<div id="machine-learning-coursework">
<h1>
<a id="machine-learning-coursework" class="anchor" href="#machine-learning-coursework" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning Coursework</h1>
<div id="introduction">
<h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<p>In this work, we aim to predict the activities undertaken by subjects based on accelerometerdata provided by the human activity recognition group (HAR): <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>. The training data concerns 6 subjects performing 5 activities (A,B,C,D,E), some correct and some incorrect. Accelerometer data include X-, Y-, Z- movement, pitch, yaw, and roll for sensors on different parts of the body.</p>
<p>Machine learning models were built from this training data in order to predict the activities in 20 tests, based on data from accelerometers, gyroscopes etc. alone.</p>
</div>

<div id="reading-in-data">
<h2>
<a id="reading-in-data" class="anchor" href="#reading-in-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reading in data</h2>
<p>We begin by reading in the provided data.</p>
<pre><code>training &lt;- read.csv("pml-training.csv")
testing &lt;- read.csv("pml-testing.csv")</code></pre>
<p>Many of the columns are empty or NA except for when a new window starts, while others give information such as the name of the subject, and the time of the activity. The test data do not have the information provided in the new window columns. Useful columns seem to be 8-11, 37-49, 60-68, 84-86, 113-124, 151-160.</p>
</div>

<div id="building-the-model">
<h2>
<a id="building-the-model" class="anchor" href="#building-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building the model</h2>
<div id="initial-work">
<h3>
<a id="initial-work" class="anchor" href="#initial-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initial work</h3>
<p>Given that there were 6 subjects, a natural method for cross validation is to predict on one subject and test it on other subjects in the training data. The first subject is âCarlitosâ, so we build the first model with his data.</p>
<p>We use a random forest model, which makes numerous decision trees for selecting the class, then votes on the best outcome for each set of predictors.</p>
<pre><code>library(caret)</code></pre>
<pre><code>## Warning: package 'caret' was built under R version 3.2.2</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<pre><code>set.seed(123456)
carlitos &lt;- training[training$user_name=="carlitos",c(8:11,37:49,60:68,84:86,113:124,151:160)]
modFit1 &lt;- train(factor(classe)~.,method="rf",data=carlitos)</code></pre>
<pre><code>## Loading required package: randomForest</code></pre>
<pre><code>## Warning: package 'randomForest' was built under R version 3.2.2</code></pre>
<pre><code>## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code># Save model here to avoid re running it in multiple compiles
saveRDS(modFit1,file="mod1")
modFit1&lt;- readRDS("mod1")</code></pre>
<p>We compare the predicted values of each excercise with the âclasseâ variable.</p>
<pre><code>prediction1 &lt;- predict(modFit1, carlitos)
confusionMatrix(carlitos$classe,prediction1)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   A   B   C   D   E
##          A 834   0   0   0   0
##          B   0 690   0   0   0
##          C   0   0 493   0   0
##          D   0   0   0 486   0
##          E   0   0   0   0 609
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9988, 1)
##     No Information Rate : 0.268      
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar's Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000   1.0000   1.0000   1.0000   1.0000
## Specificity             1.000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value          1.000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value          1.000   1.0000   1.0000   1.0000   1.0000
## Prevalence              0.268   0.2217   0.1584   0.1562   0.1957
## Detection Rate          0.268   0.2217   0.1584   0.1562   0.1957
## Detection Prevalence    0.268   0.2217   0.1584   0.1562   0.1957
## Balanced Accuracy       1.000   1.0000   1.0000   1.0000   1.0000</code></pre>
<p>We see the prediction to be near-perfect, but random forests are prone to overfitting. When we compare with Euricoâs data, we find very poor matching; everything is assigned classe = B or E.</p>
<pre><code>eurico &lt;- training[training$user_name=="eurico",c(8:11,37:49,60:68,84:86,113:124,151:160)]
confusionMatrix(eurico$classe,predict(modFit1,eurico))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   A   B   C   D   E
##          A   0 218   0   0 647
##          B   0  13   0   0 579
##          C   0  29   0   0 460
##          D   0   3   0   0 579
##          E   0  25   0   0 517
## 
## Overall Statistics
##                                           
##                Accuracy : 0.1726          
##                  95% CI : (0.1594, 0.1865)
##     No Information Rate : 0.9062          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : -0.0066         
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity                NA 0.045139       NA       NA   0.1858
## Specificity            0.7182 0.791876   0.8407   0.8104   0.9132
## Pos Pred Value             NA 0.021959       NA       NA   0.9539
## Neg Pred Value             NA 0.889023       NA       NA   0.1040
## Prevalence             0.0000 0.093811   0.0000   0.0000   0.9062
## Detection Rate         0.0000 0.004235   0.0000   0.0000   0.1684
## Detection Prevalence   0.2818 0.192834   0.1593   0.1896   0.1765
## Balanced Accuracy          NA 0.418508       NA       NA   0.5495</code></pre>
</div>

<div id="modeling-the-normalised-standardised-data-for-carlitos">
<h3>
<a id="modeling-the-normalised-standardised-data-for-carlitos" class="anchor" href="#modeling-the-normalised-standardised-data-for-carlitos" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modeling the normalised, standardised data for Carlitos</h3>
<p>Using the preProcess command, we can normalise and standardise the data for each subject, then training a model based on that .</p>
<pre><code>preProc &lt;- preProcess(carlitos[,-51],method=c("center","scale"))
carlitos_norm &lt;- predict(preProc,carlitos[,-51])
set.seed(5464)
modFit2 &lt;- train(factor(carlitos$classe)~.,method="rf",data=carlitos_norm)

#  Save model here to avoid re running it in multiple compiles
saveRDS(modFit2,file="mod2")
modFit2&lt;- readRDS("mod2")

confusionMatrix(carlitos$classe,predict(modFit2,carlitos_norm))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   A   B   C   D   E
##          A 834   0   0   0   0
##          B   0 690   0   0   0
##          C   0   0 493   0   0
##          D   0   0   0 486   0
##          E   0   0   0   0 609
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9988, 1)
##     No Information Rate : 0.268      
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar's Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000   1.0000   1.0000   1.0000   1.0000
## Specificity             1.000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value          1.000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value          1.000   1.0000   1.0000   1.0000   1.0000
## Prevalence              0.268   0.2217   0.1584   0.1562   0.1957
## Detection Rate          0.268   0.2217   0.1584   0.1562   0.1957
## Detection Prevalence    0.268   0.2217   0.1584   0.1562   0.1957
## Balanced Accuracy       1.000   1.0000   1.0000   1.0000   1.0000</code></pre>
<pre><code>#Compare with other, making sure to use SD and mean from sample
eurico_norm &lt;- predict(preProc,eurico[,-51])
confusionMatrix(eurico$classe,predict(modFit2,eurico_norm))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   A   B   C   D   E
##          A   0 278   0   0 587
##          B   0   9   0   0 583
##          C   0   2   0   0 487
##          D   0   2   0   0 580
##          E   0  20   0   0 522
## 
## Overall Statistics
##                                           
##                Accuracy : 0.173           
##                  95% CI : (0.1597, 0.1868)
##     No Information Rate : 0.8987          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : -0.0064         
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity                NA 0.028939       NA       NA   0.1892
## Specificity            0.7182 0.788692   0.8407   0.8104   0.9357
## Pos Pred Value             NA 0.015203       NA       NA   0.9631
## Neg Pred Value             NA 0.878128       NA       NA   0.1151
## Prevalence             0.0000 0.101303   0.0000   0.0000   0.8987
## Detection Rate         0.0000 0.002932   0.0000   0.0000   0.1700
## Detection Prevalence   0.2818 0.192834   0.1593   0.1896   0.1765
## Balanced Accuracy          NA 0.408815       NA       NA   0.5624</code></pre>
<p>This is about the same.</p>
</div>

<div id="random-forest-of-whole-sample">
<h3>
<a id="random-forest-of-whole-sample" class="anchor" href="#random-forest-of-whole-sample" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random forest of whole sample</h3>
<p>The next step in model building was to make a random forest model for everybody involved. First, the entire sample was centered and scaled.</p>
<pre><code>trim &lt;- training[,c(8:11,37:49,60:68,84:86,113:124,151:160)]
preProc &lt;- preProcess(trim[,-51],method=c("scale","center"))
trim_prep &lt;- predict(preProc,trim[,-51])</code></pre>
<p>Next, the training data were split into test and training subsets (3:1 split). We needed to make the same splits for the trimmed data and prepared data because the prepared data is missing the outcome column.</p>
<pre><code>inTrain &lt;-  createDataPartition(factor(trim$classe),p= 3/4)[[1]]
trim_train &lt;- training[inTrain,]
trim_test &lt;- training[-inTrain,]

prep_train &lt;- trim_prep[inTrain,]
prep_test &lt;- trim_prep[-inTrain,]</code></pre>
<p>We created a new model, and tested it on the training set</p>
<pre><code>set.seed(5673)
modFit3 &lt;- train(factor(trim_train$classe)~.,method="rf",data=prep_train)

#  Save model here to avoid re running it in multiple compiles
saveRDS(modFit3,file="mod3")
modFit3&lt;- readRDS("mod3")
modFit3$finalModel</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 0.64%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 4183    1    0    0    1 0.0004778973
## B   11 2832    5    0    0 0.0056179775
## C    0   14 2547    6    0 0.0077911959
## D    0    0   42 2367    3 0.0186567164
## E    0    0    2    9 2695 0.0040650407</code></pre>
<pre><code>confusionMatrix(trim_train$classe,predict(modFit3,prep_train))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 4185    0    0    0    0
##          B    0 2848    0    0    0
##          C    0    0 2567    0    0
##          D    0    0    0 2412    0
##          E    0    0    0    0 2706
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9997, 1)
##     No Information Rate : 0.2843     
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar's Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1839
## Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1839
## Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1839
## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000</code></pre>
<p>Again we saw 100% success rate. We then tried it on the testing subset of the training data (which has the same standard deviation and mean for each column).</p>
<pre><code>confusionMatrix(trim_test$classe,predict(modFit3,prep_test))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1394    1    0    0    0
##          B    2  944    3    0    0
##          C    0    5  846    4    0
##          D    0    0   15  789    0
##          E    0    0    0    0  901
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9939          
##                  95% CI : (0.9913, 0.9959)
##     No Information Rate : 0.2847          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9923          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9986   0.9937   0.9792   0.9950   1.0000
## Specificity            0.9997   0.9987   0.9978   0.9964   1.0000
## Pos Pred Value         0.9993   0.9947   0.9895   0.9813   1.0000
## Neg Pred Value         0.9994   0.9985   0.9956   0.9990   1.0000
## Prevalence             0.2847   0.1937   0.1762   0.1617   0.1837
## Detection Rate         0.2843   0.1925   0.1725   0.1609   0.1837
## Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837
## Balanced Accuracy      0.9991   0.9962   0.9885   0.9957   1.0000</code></pre>
<p>This is highly encouraging, with accuracy better than 99%, a huge improvement. However, this is likely to be too high, given that the training and test samples have the same means and standard deviations. In order to estimate out of sample error, we apply it to Carlitosâand Euricoâs data, using the mean and standard deviations of the training sample. The means and standard deviations for individuals are expected to vary from those of the group. plot(modFit3)</p>
<pre><code># This pre processing uses whole training SDs and means
carlitos_prep &lt;- predict(preProc,carlitos[,-51])
oos_predict &lt;- predict(modFit3,carlitos_prep)
confusionMatrix(carlitos$classe,oos_predict)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   A   B   C   D   E
##          A 834   0   0   0   0
##          B   1 689   0   0   0
##          C   0   1 492   0   0
##          D   0   0   0 486   0
##          E   0   0   0   0 609
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9994          
##                  95% CI : (0.9977, 0.9999)
##     No Information Rate : 0.2683          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9992          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9988   0.9986   1.0000   1.0000   1.0000
## Specificity            1.0000   0.9996   0.9996   1.0000   1.0000
## Pos Pred Value         1.0000   0.9986   0.9980   1.0000   1.0000
## Neg Pred Value         0.9996   0.9996   1.0000   1.0000   1.0000
## Prevalence             0.2683   0.2217   0.1581   0.1562   0.1957
## Detection Rate         0.2680   0.2214   0.1581   0.1562   0.1957
## Detection Prevalence   0.2680   0.2217   0.1584   0.1562   0.1957
## Balanced Accuracy      0.9994   0.9991   0.9998   1.0000   1.0000</code></pre>
<p>Now try Eurico</p>
<pre><code>eurico_prep &lt;- predict(preProc,eurico[,-51])
oos_predict2 &lt;- predict(modFit3,eurico_prep)
confusionMatrix(eurico$classe,oos_predict2)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   A   B   C   D   E
##          A 864   1   0   0   0
##          B   0 592   0   0   0
##          C   0   1 488   0   0
##          D   0   0   0 582   0
##          E   0   0   0   0 542
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9993          
##                  95% CI : (0.9976, 0.9999)
##     No Information Rate : 0.2814          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9992          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9966   1.0000   1.0000   1.0000
## Specificity            0.9995   1.0000   0.9996   1.0000   1.0000
## Pos Pred Value         0.9988   1.0000   0.9980   1.0000   1.0000
## Neg Pred Value         1.0000   0.9992   1.0000   1.0000   1.0000
## Prevalence             0.2814   0.1935   0.1590   0.1896   0.1765
## Detection Rate         0.2814   0.1928   0.1590   0.1896   0.1765
## Detection Prevalence   0.2818   0.1928   0.1593   0.1896   0.1765
## Balanced Accuracy      0.9998   0.9983   0.9998   1.0000   1.0000</code></pre>
</div>

<div id="estimating-the-uncertainties">
<h3>
<a id="estimating-the-uncertainties" class="anchor" href="#estimating-the-uncertainties" aria-hidden="true"><span class="octicon octicon-link"></span></a>Estimating the uncertainties</h3>
<p>The random forest method yields several estimates of the out of sample uncertainties. The first is the âout of bagâ uncertaintity generated by the random forest model itself, 0.66%. We can also look at the accuracies of the model fits for individual data, since the means and standard deviations will differ from those used in generating the model. The tests with Carlitosâ and Euricoâs data, yield 95% confdidence lower limits for accuracy of 99.9% and 99.62% respectively. We assume the largest uncertainty of these, 0.66%.</p>
</div>

<p></p>
</div>

<div id="running-the-test.">
<h2>
<a id="running-the-test" class="anchor" href="#running-the-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Running the test.</h2>
<p>We now filter the test set, then scale and centre the test data.</p>
<pre><code>test &lt;- testing[,c(8:11,37:49,60:68,84:86,113:124,151:160)]
test_prep &lt;- predict(preProc,test[,-51])
preds &lt;- predict(modFit3,test_prep)</code></pre>
<p>Cue fanfareâ¦ here are the predictions:</p>
<pre><code>preds</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
<p>All that remains is to write the funtion to get them ready for submission.</p>
<pre><code>pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(preds)</code></pre>
<p>We scored 100%!</p>
</div>

<p></p>
</div>

<p></p>
</div>







<p>
</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Machine-learning-project maintained by <a href="https://github.com/drr0b">drr0b</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
